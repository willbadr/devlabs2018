{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MXNET libraries and some other dependencies.\n",
    "In the next block, I will download the resnet model as the pretrained model for image recognition then I will use it to carry out a transfer learning of the flower species recognition. In this demo, I will also be using CloudWatch to monitor the model performance through CloudWatch Dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib\n",
    "import mxnet as mx\n",
    "import sagemaker_cw\n",
    "from sagemaker_cw import CWEvalMetrics\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "def get_model(prefix, epoch):\n",
    "    download(prefix+'-symbol.json')\n",
    "    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "get_model('http://data.mxnet.io/models/imagenet/resnet/50-layers/resnet-50', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-trained ResNet model and make it ready for training on flowers\n",
    "I simply use the MXNet Model load_checkpoint function to load the 50 layers pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-50', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Visualize the ResNet pretrained model\n",
    "This step is an optional step to visualize the ResNet network. You can also compare the network before and after we do the Transfer Learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.viz.plot_network(sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create a dataset iterator\n",
    "We will create MXNet dataset iteration to iterate on the images in the dataset. The dataset has been prepared and processed in the RecordIO format as discussed in the instructions guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterators(batch_size, data_shape=(3, 224, 224)):\n",
    "    train = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = './dataset/102flowers-train.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        shuffle             = True,\n",
    "        rand_crop           = True,\n",
    "        rand_mirror         = True)\n",
    "    val = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = './dataset/102flowers-valid.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        rand_crop           = False,\n",
    "        rand_mirror         = False)\n",
    "    return (train, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the transfer knowledge function\n",
    "In this function, we will replace the output layer with a new layer that has the new number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_knowledge_to_model(symbol, arg_params, num_classes, layer_name='flatten0'):\n",
    "    \"\"\"\n",
    "    symbol: the pre-trained network symbol\n",
    "    arg_params: the argument parameters of the pre-trained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = sym.get_internals()\n",
    "    net = all_layers[layer_name+'_output']\n",
    "    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc1')\n",
    "    net = mx.symbol.SoftmaxOutput(data=net, name='softmax')\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if 'fc1' not in k})\n",
    "    return (net, new_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'batch_size': 100, \n",
    "                         'epochs': 5,\n",
    "                         'kvstore': 'device',\n",
    "                         'optimizer':  'sgd',\n",
    "                         'learning_rate': 0.01, \n",
    "                         'momentum': 0.9, \n",
    "                         'log_interval': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define performance monitoring function using CloudWatch\n",
    "In this function, we will integrate the Model performance metrics with CloudWatch by sending the trainging metrics and visualizing the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "cw_logger = logging.getLogger('botocore')\n",
    "cw_logger.setLevel(logging.CRITICAL)\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "last_count = 0\n",
    "frequent = 10\n",
    "init = False\n",
    "tic = 0\n",
    "\n",
    "def log_train_metric(auto_reset=False, hyperparameters=hyperparameters):\n",
    "    batch_size = hyperparameters.get('batch_size')\n",
    "    auto_reset = auto_reset\n",
    "    \n",
    "    def _callback(param):\n",
    "        \"\"\"The checkpoint function.\"\"\"\n",
    "        global last_count\n",
    "        global frequent\n",
    "        global init\n",
    "        global tic\n",
    "        count = param.nbatch\n",
    "        if last_count > count:\n",
    "            init = False\n",
    "        else:\n",
    "            init = True\n",
    "        last_count = count\n",
    "        if init:\n",
    "            if count % frequent == 0:\n",
    "                speed = frequent * batch_size / (time.time() - tic)\n",
    "                if param.eval_metric is not None:\n",
    "                    name_value = param.eval_metric.get_name_value()\n",
    "                    if auto_reset:\n",
    "                        param.eval_metric.reset()\n",
    "                    for name, acc_value in name_value:\n",
    "                        #logging.info('Iter[%d] Batch[%d] Train-%s=%f',\n",
    "                         #        param.epoch, param.nbatch, name, acc_value)\n",
    "                        CWMetrics = CWEvalMetrics()\n",
    "                        CWMetrics.CW_eval(model_name='sydsummit1',is_training=True, Accuracy=acc_value * 100, Loss=0, hyperparameters=hyperparameters)\n",
    "                    if auto_reset:\n",
    "                        param.eval_metric.reset()\n",
    "                    msg = 'Epoch[%d] Batch [%d]\\tSpeed: %.2f samples/sec'\n",
    "                    msg += '\\t%s=%f'*len(name_value)\n",
    "                    logging.info(msg, param.epoch, count, speed, *sum(name_value, ()))\n",
    "                else:\n",
    "                    logging.info(\"Iter[%d] Batch [%d]\\tSpeed: %.2f samples/sec\",\n",
    "                                 param.epoch, count, speed)\n",
    "                tic = time.time()\n",
    "            else:\n",
    "                init = True\n",
    "                tic = time.time()\n",
    "    return _callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training function and setting the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 102\n",
    "batch_per_gpu = 20\n",
    "num_gpus = 1\n",
    "def fit(symbol, arg_params, aux_params, train, val, batch_size, num_gpus):\n",
    "    devs = [mx.gpu(i) for i in range(num_gpus)]\n",
    "    mod = mx.mod.Module(symbol=new_sym, context=devs)\n",
    "    epochs = hyperparameters.get('epochs')\n",
    "    mod.fit(train, val, \n",
    "        num_epoch=epochs,\n",
    "        arg_params=arg_params,\n",
    "        aux_params=aux_params,\n",
    "        allow_missing=True,\n",
    "        #batch_end_callback = mx.callback.Speedometer(batch_size, 10),\n",
    "        batch_end_callback = log_train_metric(),\n",
    "        eval_metric='acc',\n",
    "        kvstore='device',\n",
    "        optimizer='sgd',\n",
    "        epoch_end_callback  = mx.callback.do_checkpoint(\"102flowers\", 1),\n",
    "        optimizer_params={'learning_rate':0.01},\n",
    "        initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2))\n",
    "    metric = mx.metric.Accuracy()\n",
    "    return mod.score(val, metric)\n",
    "(new_sym, new_args) = transfer_knowledge_to_model(sym, arg_params, num_classes)\n",
    "batch_size = batch_per_gpu * num_gpus\n",
    "(train, val) = get_iterators(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Visualize the new network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.viz.plot_network(new_sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the model training\n",
    "The training process should take about 4-5 minutes to finish. It will save a checkpoint after each EPOCH and you will get the last checkpoint and upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date\n",
    "mod_score = fit(new_sym, new_args, aux_params, train, val, batch_size, num_gpus)\n",
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the model artifacts to S3\n",
    "We will use the model artifact later on in the deployment stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "bucket=\"sagemaker-demo-sydsummit\"\n",
    "def upload_to_s3(channel, file):\n",
    "    s3 = boto3.resource('s3')\n",
    "    data = open(file, \"rb\")\n",
    "    key = channel + '/' + file\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data)\n",
    "\n",
    "epochs = hyperparameters.get('epochs')\n",
    "model_fname = \"102flowers-000\" + str(epochs) + \".params\"\n",
    "upload_to_s3('artifacts', model_fname)\n",
    "upload_to_s3('artifacts', '102flowers-symbol.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deploy the model\n",
    "There are two ways to deploy the model artifacts:\n",
    "\n",
    "1- Deploy the model through Sagemaker by running the \"estimator.deploy()\" function. (BUT, that's too easy')\n",
    "\n",
    "2- Deploy a complete serverless endpoint using Lambda and API Gateway (That's so much cooler, cost effective and it's an on-demand endpoint)\n",
    "\n",
    "I've create a CloudFormation template to deploy the serverless stack to host our model. Click on the below link to lunch the stack and follow the default wizard.\n",
    "\n",
    "[Deploy CloudFormation Template](https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=Flowers-Recognition-Template&templateURL=https://s3-us-west-2.amazonaws.com/sagemaker-demo-sydsummit/demo-code/102flowers.template)\n",
    "\n",
    "After the deployment is finished, get back to the Demo Instructions sheet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p27",
   "language": "python",
   "name": "conda_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
